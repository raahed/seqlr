{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecb1ff0-9338-497e-96db-a7be28d470ea",
   "metadata": {},
   "source": [
    "# Assignment 1: Decoding States\n",
    "\n",
    "---\n",
    "\n",
    "## Task 5) Dual-Tone Multi-Frequency\n",
    "\n",
    "[Dual-tone multi-frequency DTMF](https://en.wikipedia.org/wiki/Dual-tone_multi-frequency_signaling) signaling is an old way of transmitting dial pad keystrokes over the phone.\n",
    "Each key/symbol is assigned a frequency pair: `[(1,697,1209), (2,697,1336), (3,697,1477), (A,697,1633), (4,770,1209), (5,770,1336), (6,770,1477), (B,770,1633), (7,852,1209), (8,852,1336), (9,852,1477), (C,852,1633), (*,941,1209), (0,941,1336), (#,941,1477), (D,941,1633)]`.\n",
    "You can generate some DTMF sequences online, eg. <https://www.audiocheck.net/audiocheck_dtmf.php>\n",
    "\n",
    "### Features\n",
    "\n",
    "For feature computation, use librosa to compute the power spectrum (`librosa.stft` and `librosa.amplitude_to_db`), and extract the approx. band energy for each relevant frequency.\n",
    "\n",
    "> Note: It's best to identify silence by the overall spectral energy and to normalize the band energies to sum up to one.\n",
    "\n",
    "### Decoding\n",
    "\n",
    "To decode DTMF sequences, we can use again dynamic programming, this time applied to states rather than edits.\n",
    "For DTMF sequences, consider a small, fully connected graph that has 13 states: 0-9, A-D, \\*, \\# and _silence_.\n",
    "As for the DP-matrix: the rows will denote the states and the columns represent the time; we will decode left-to-right (ie. time-synchronous), and at each time step, we will have to find the best step forward.\n",
    "The main difference to edit distances or DTW is, that you may now also \"go up\" in the table, ie. change state freely.\n",
    "For distance/similarity, use a template vector for each state that has `.5` for those two bins that need to be active.\n",
    "\n",
    "When decoding a sequence, the idea is now that we remain in one state as long as the key is pressed; after that, the key may either be released (and the spectral energy is close to 0) hence we're in pause, or another key is pressed, hence it's a \"direct\" transition.\n",
    "Thus, from the backtrack, collapse the sequence by digit and remove silence, eg. `44443-3-AAA` becomes `433A`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7aee7c-59a1-4fa9-927e-5297cdaa95c3",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49652ab4-1773-44b9-8505-0c812522a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76709f02-d408-4da4-9608-3336bff8e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notice: librosa defaults to 22.050 Hz sample rate; adjust if needed!\n",
    "\n",
    "DTMF_TONES = [\n",
    "    ('1', 697, 1209), \n",
    "    ('2', 697, 1336), \n",
    "    ('3', 697, 1477), \n",
    "    ('A', 697, 1633),\n",
    "    ('4', 770, 1209),\n",
    "    ('5', 770, 1336),\n",
    "    ('6', 770, 1477),\n",
    "    ('B', 770, 1633),\n",
    "    ('7', 852, 1209),\n",
    "    ('8', 852, 1336),\n",
    "    ('9', 852, 1477),\n",
    "    ('C', 852, 1633),\n",
    "    ('*', 941, 1209),\n",
    "    ('0', 941, 1336),\n",
    "    ('#', 941, 1477),\n",
    "    ('D', 941, 1633)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa95de0-393a-4b94-959b-dda2472a320b",
   "metadata": {},
   "source": [
    "### Implement the Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f97841-2092-41dc-8580-9356f82cd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO:\n",
    "### 1. familiarize with librosa stft to compute powerspectrum\n",
    "### 2. extract the critical bands from the power spectrum (ie. how much energy in the DTMF-related freq bins?)\n",
    "### 3. define template vectors representing the state (see dtmf_tones)\n",
    "### 4. for a new recording, extract critical bands and do DP do get state sequence\n",
    "### 5. backtrack & collapse\n",
    "\n",
    "### Notice: you will need a couple of helper functions...\n",
    "ALL_DTMFS = [697, 770, 852, 941, 1209, 1336, 1477, 1633]\n",
    "\n",
    "def similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return np.linalg.norm(b - a)\n",
    "\n",
    "def decode_column(col: np.ndarray, dtmf_templates: list) -> str:\n",
    "    best_label, best_score = None, float('inf')\n",
    "    for label, template in dtmf_templates:\n",
    "        score = similarity(col, template)\n",
    "        if score < best_score:\n",
    "            best_label, best_score = label, score\n",
    "    return best_label\n",
    "\n",
    "def decode(y: np.ndarray, sr: float):\n",
    "    \"\"\"\n",
    "    Apply DTMF signal decoding.\n",
    "\n",
    "    Arguments:\n",
    "    y: Input signal.\n",
    "    sr: Sample rate.\n",
    "\n",
    "    Returns list of DTMF-signals (no silence).\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)\n",
    "    freqs = freqs[freqs <= 2000]  # Limit to 0 - 2000 Hz\n",
    "    \n",
    "    nearest_freqs = {f: np.argmin(np.abs(freqs - f)) for f in ALL_DTMFS}\n",
    "    \n",
    "    dtmf_templates = []\n",
    "    for (label, low, high) in DTMF_TONES:\n",
    "        template = np.zeros_like(freqs)\n",
    "        template[nearest_freqs[low]] = 0.5\n",
    "        template[nearest_freqs[high]] = 0.5\n",
    "        dtmf_templates.append((label, template))\n",
    "    \n",
    "    silence_template = np.full(len(freqs), 1 / len(freqs))\n",
    "    dtmf_templates.append((None, silence_template))\n",
    "    \n",
    "    D = librosa.stft(y, n_fft=2048)\n",
    "    D = np.abs(D[:len(freqs), :]) ** 2\n",
    "    D /= np.sum(D, axis=0, where=(np.sum(D, axis=0) != 0), keepdims=True)\n",
    "    \n",
    "    decoded = [decode_column(D[:, i], dtmf_templates) for i in range(D.shape[1])]\n",
    "    result = [x for i, x in enumerate(decoded) if x != decoded[i-1] and x is not None]\n",
    "    return ''.join(result)\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750c234-6007-42ca-9b9c-2e6b5bfa9bbb",
   "metadata": {},
   "source": [
    "### Test the Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1de6d88b-546d-4f43-a4aa-6745c02e112b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11216311219611#9632##9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45264/4106786498.py:55: RuntimeWarning: invalid value encountered in divide\n",
      "  D /= np.sum(D, axis=0, where=(np.sum(D, axis=0) != 0), keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "SR = 22050\n",
    "TEST_FILE = \"data/audiocheck.net_dtmf_112163_112196_11#9632_##9696.wav\"\n",
    "\n",
    "y, sr = librosa.load(TEST_FILE, sr=SR)\n",
    "print(decode(y=y, sr=sr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
