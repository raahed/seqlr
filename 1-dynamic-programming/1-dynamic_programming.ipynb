{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51f3ab5-22c7-4ead-9169-494e12e73c1a",
   "metadata": {},
   "source": [
    "# Assignment 1: Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0361ad-79a6-4492-b080-ee8bcf8ca4de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1) Edit Distances\n",
    "\n",
    "Implement the [Hamming](https://en.wikipedia.org/wiki/Hamming_distance) and [Levenshtein](https://en.wikipedia.org/wiki/Levenshtein_distance) (edit) distances and compute them for the for the following word pairs.\n",
    "It may help to compute them by hand first.\n",
    "\n",
    "<img src = \"./assets/97090.jpg\" width=\"33%\" /> <img src = \"./assets/97222.jpg\" width=\"33%\" /> <img src = \"./assets/97669.jpg\" width=\"33%\" />\n",
    "\n",
    "Aside from computing the distance (which is a scalar), do the backtrace and compute the edit transcript (and thus alignment).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b947e856-5284-4cf2-922f-c44268c365ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_PAIRS = [\n",
    "    (\"GCGTATGAGGCTAACGC\", \"GCTATGCGGCTATACGC\"),\n",
    "    (\"kühler schrank\", \"schüler krank\"),\n",
    "    (\"the longest\", \"longest day\"),\n",
    "    (\"nicht ausgeloggt\", \"licht ausgenockt\"),\n",
    "    (\"gurken schaben\", \"schurkengaben\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb02c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(s1: str, s2: str) -> tuple[str, str]:\n",
    "    \"\"\"\"\n",
    "    Align two strings by padding the shorter string with spaces.\n",
    "    \"\"\"\n",
    "    max_len = max(len(s1), len(s2))\n",
    "    return (s1.ljust(max_len), s2.ljust(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7f504ef-3822-44fe-986f-88b4ca791017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming(s1: str, s2: str) -> int:\n",
    "    \"\"\"\n",
    "    Compute the hamming distance between two strings.\n",
    "\n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "\n",
    "    Returns the distance as int.\n",
    "    \"\"\"\n",
    "    # Hint: Think about how you can deal with unequal word lengths.\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    s1, s2 = align(s1, s2)\n",
    "\n",
    "    d = 0\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        if s1[i] != s2[i]:\n",
    "            d += 1\n",
    "    \n",
    "    return d\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11a59e5d-2bcc-40d6-b3b8-c24d886bc9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 10\n",
      "hamming('kühler schrank', 'schüler krank') = 13\n",
      "hamming('the longest', 'longest day') = 11\n",
      "hamming('nicht ausgeloggt', 'licht ausgenockt') = 4\n",
      "hamming('gurken schaben', 'schurkengaben') = 14\n"
     ]
    }
   ],
   "source": [
    "for wordpair in WORD_PAIRS:\n",
    "    dist = hamming(s1=wordpair[0], s2=wordpair[1])\n",
    "    print(\"hamming('{}', '{}') = {}\".format(\n",
    "        wordpair[0], wordpair[1], dist\n",
    "    ))\n",
    "\n",
    "### EXPECTED\n",
    "# hamming('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 10\n",
    "# hamming('kühler schrank', 'schüler krank') = 13\n",
    "# hamming('the longest', 'longest day') = 11\n",
    "# hamming('nicht ausgeloggt', 'licht ausgenockt') = 4\n",
    "# hamming('gurken schaben', 'schurkengaben') = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef05b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9791159e-0511-44d1-9e39-481942835d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(s1: str, s2: str, cost={'m': 0, 's': 1, 'i': 1, 'd': 1}) -> tuple[int, str]:\n",
    "    \"\"\"\n",
    "    Compute the levenshtein (edit) distance between two strings.\n",
    "\n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "\n",
    "    Returns the distance as int and edit transcript as string.\n",
    "    \"\"\"\n",
    "    # Hint: The probably most intuitive approach is bottom-up.\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    x, y = len(s1), len(s2)\n",
    "    m = ''\n",
    "    D = np.zeros(shape=(x + 1, y + 1), dtype = int)\n",
    "    D[0, 1:] = range(1, y + 1)\n",
    "    D[1:, 0] = range(1, x + 1)\n",
    "    \n",
    "    # Fill the table\n",
    "    for i in range(1, x + 1):\n",
    "        for j in range(1, y + 1):\n",
    "            d = cost['m'] if s1[i - 1] == s2[j - 1] else cost['s']\n",
    "            u = D[i - 1, j] + cost['d']\n",
    "            l = D[i, j - 1] + cost['i']\n",
    "            ul = D[i - 1, j - 1] + d\n",
    "            D[i, j] = min(u, l, ul)\n",
    "\n",
    "    # Write the transcript\n",
    "    i, j = x, y\n",
    "    while i > 0 or j > 0:\n",
    "        c = D[i, j]\n",
    "        if i > 0 and c == D[i - 1, j] + cost['d']:\n",
    "            m += 'd'\n",
    "            i, j = i - 1, j     \n",
    "        elif j > 0 and c == D[i, j - 1] + cost['i']:\n",
    "            m += 'i'\n",
    "            i, j = i, j - 1\n",
    "        else:\n",
    "            if c == D[i - 1, j - 1] + cost['s'] and s1[i - 1] != s2[j - 1]:\n",
    "                m += 's'\n",
    "            else:\n",
    "                m += 'm'\n",
    "            i, j = i - 1, j - 1\n",
    "\n",
    "    return D[-1, -1], m[::-1]\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b794add6-0ee0-4a64-a79f-4b0e68d3a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levenshtein('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 3 (mmdmmmmsmmmmmimmmm)\n",
      "levenshtein('kühler schrank', 'schüler krank') = 6 (ssmimmmmsddmmmm)\n",
      "levenshtein('the longest', 'longest day') = 8 (ddddmmmmmmmiiii)\n",
      "levenshtein('nicht ausgeloggt', 'licht ausgenockt') = 4 (smmmmmmmmmmsmssm)\n",
      "levenshtein('gurken schaben', 'schurkengaben') = 7 (siimmmmmsdddmmmm)\n"
     ]
    }
   ],
   "source": [
    "for wordpair in WORD_PAIRS:\n",
    "    dist, transcript = levenshtein(s1=wordpair[0], s2=wordpair[1])\n",
    "    print(\"levenshtein('{}', '{}') = {} ({})\".format(\n",
    "        wordpair[0], wordpair[1], dist, transcript\n",
    "    ))\n",
    "\n",
    "### EXPECTED\n",
    "# levenshtein('GCGTATGAGGCTAACGC', 'GCTATGCGGCTATACGC') = 3 (mmdmmmmsmmmmmimmmm)\n",
    "# levenshtein('kühler schrank', 'schüler krank') = 6 (ssmimmmmsddmmmm)\n",
    "# levenshtein('the longest', 'longest day') = 8 (ddddmmmmmmmiiii)\n",
    "# levenshtein('nicht ausgeloggt', 'licht ausgenockt') = 4 (smmmmmmmmmmsmssm)\n",
    "# levenshtein('gurken schaben', 'schurkengaben') = 7 (siimmmmmsdddmmmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84084e8a-f48d-45a6-8f8d-199981dc0aa7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2) Basic Spelling Correction using Edit Distance\n",
    "\n",
    "For spelling correction, we will use prior knowledge, to put _some_ learning into our system.\n",
    "\n",
    "The underlying idea is the _Noisy Channel Model_, that is: The user _intends_ to write a word `w`, but through some noise in the process, happens to type the word `x`.\n",
    "\n",
    "The correct word $\\hat{w}$ is that word, that is a valid candidate and has the highest probability:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\DeclareMathOperator*{\\argmax}{argmax}\n",
    "\\hat{w} & = & \\argmax_{w \\in V} P(w | x) \\\\\n",
    "        & = & \\argmax_{w \\in V} \\frac{P(x|w) P(w)}{P(x)} \\\\\n",
    "        & = & \\argmax_{w \\in V} P(x|w) P(w)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "1. The candidates $V$ can be obtained from a _vocabulary_.\n",
    "2. The probability $P(w)$ of a word $w$ can be _learned (counted) from data_.\n",
    "3. The probability $P(x|w)$ is more complicated... It could be learned from data, but we could also use a _heuristic_ that relates to the edit distance, e.g. rank by distance.\n",
    "\n",
    "You may use [Peter Norvig's count_1w.txt](http://norvig.com/ngrams/) file, [local mirror](res/count_1w.tar.bz2).\n",
    "Note that it may help to restrict to the first 10k words to get started.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7190fb5-93c5-456b-835b-32a73d0f3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = [\n",
    "    \"pirates\",    # in-voc\n",
    "    \"pirutes\",    # pirates?\n",
    "    \"continoisly\",  # continuosly?\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08adedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce0ead32-59de-42c4-b488-a56001931fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Prepare the vocabulary\n",
    "\n",
    "### YOUR CODE HERE\n",
    "V = pd.read_csv('data/count_1w.txt', delimiter='\\t', header=None, names=['word', 'counting'], dtype={'word': str, 'counting': int})\n",
    "V = V.sort_values(by='counting', ascending=False).head(100000)\n",
    "V = V.drop('counting', axis=1)\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f88150c8-3d00-483e-8682-1f6720d2a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest(w: str, dist_fn, max_cand=5) -> list[tuple[str, int, int]]:\n",
    "    \"\"\"\n",
    "    Compute suggestions for spelling correction using edit distance.\n",
    "    \n",
    "    Arguments:\n",
    "    w: Word in question.\n",
    "    dist_fn: Distance function to use (e.g. levenshtein).\n",
    "    max_cand: Maximum number of suggestions.\n",
    "\n",
    "    Returns a list of tuples (word, dist, score) sorted by score and distance.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    df = V.copy()\n",
    "    df['dist'] = df['word'].apply((lambda x: dist_fn(w, str(x))[0]))\n",
    "    df.sort_values(by='dist', inplace=True)\n",
    "    return [tuple(r) for r in df.head(max_cand).to_numpy()]\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f5490ca-969c-4a93-aaf0-8cdb3433ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pirates [('pirates', 0), ('pilates', 1), ('pirated', 1)]\n",
      "pirutes [('pirates', 1), ('prunes', 2), ('picutres', 2)]\n",
      "continoisly [('continuously', 2), ('continuity', 3), ('continous', 3)]\n"
     ]
    }
   ],
   "source": [
    "# How does your suggest function behave with levenshtein distance?\n",
    "\n",
    "for word in EXAMPLES:\n",
    "    suggestions = suggest(w=word, dist_fn=levenshtein, max_cand=3)\n",
    "    print(\"{} {}\".format(word, suggestions))\n",
    "\n",
    "### EXPECTED\n",
    "### Notice: your scores may vary!\n",
    "# pirates [('pirates', 0, -11.408058827802126)]\n",
    "# pirutes [('pirates', 1, -11.408058827802126), ('minutes', 2, -8.717825438953103), ('viruses', 2, -11.111468702571859)]\n",
    "# continoisly [('continously', 1, -15.735337826575178), ('continuously', 2, -11.560071979871001), ('continuosly', 2, -17.009283000138204)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa2e00-a1dd-46e5-90c0-2f3eea3cb031",
   "metadata": {},
   "source": [
    "### Food for Thought\n",
    "\n",
    "- How would you modify the implementation so that it works fast for large lexica (eg. the full file above)?\n",
    "- How would you modify the implementation so that it works \"while typing\" instead of at the end of a word?\n",
    "- How do you handle unknown/new words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a183c2b3-7cee-420e-bb08-5748dbfed5dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3) Needleman-Wunsch: Keyboard-aware Auto-Correct\n",
    "\n",
    "In the parts 1 and 2 above, we applied uniform cost to all substitutions.\n",
    "This does not really make sense if you look at a keyboard: the QWERTY layout will favor certain substitutions (eg. _a_ and _s_), while others are fairly unlikely (eg. _a_ and _k_).\n",
    "\n",
    "Implement the [Needleman-Wunsch algorithm](https://en.wikipedia.org/wiki/Needleman–Wunsch_algorithm) which is very similar to the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance), however it doesn't _minimize the cost_ but _maximizes the similarity_.\n",
    "For a good measure of similarity, implement a metric that computes a meaningful weight for a given character substitution.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23709626-6af8-41ae-b713-f0d8c7b117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyboardsim(s1: str, s2: str) -> float:\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def nw(s1: str, s2: str, d: float, sim_fn) -> float:\n",
    "    \"\"\"\n",
    "    Apply needleman-wunsch algorithm.\n",
    "    \n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "    d: Gap penalty score.\n",
    "    sim_fn: Similarity function to use.\n",
    "\n",
    "    Returns the score as float.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def nw_based_dist(s1: str, s2: str) -> (int, str):\n",
    "    \"\"\"\n",
    "    Compute the needleman-wunsch distance between two strings.\n",
    "    \n",
    "    Arguments:\n",
    "    s1: First string of word pair.\n",
    "    s2: Second string of word pair.\n",
    "    \n",
    "    Returns the distance as int and <unsupported> string.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    # Hint: return dist, \"<unsupported>\"\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f510005-f578-4afa-99a3-9a389fd86069",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# How does your suggest function behave with nw and a keyboard-aware similarity?\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m EXAMPLES:\n\u001b[0;32m----> 4\u001b[0m     suggestions \u001b[38;5;241m=\u001b[39m \u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnw_based_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_cand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(word, suggestions))\n",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m, in \u001b[0;36msuggest\u001b[0;34m(w, dist_fn, max_cand)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 14\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtuple\u001b[39m(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mhead(max_cand)\u001b[38;5;241m.\u001b[39mto_numpy()]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m, in \u001b[0;36msuggest.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 14\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply((\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     15\u001b[0m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtuple\u001b[39m(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mhead(max_cand)\u001b[38;5;241m.\u001b[39mto_numpy()]\n",
      "Cell \u001b[0;32mIn[27], line 40\u001b[0m, in \u001b[0;36mnw_based_dist\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03mCompute the needleman-wunsch distance between two strings.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mReturns the distance as int and <unsupported> string.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# How does your suggest function behave with nw and a keyboard-aware similarity?\n",
    "\n",
    "for word in EXAMPLES:\n",
    "    suggestions = suggest(w=word, dist_fn=nw_based_dist, max_cand=3)\n",
    "    print(\"{} {}\".format(word, suggestions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63b759-ba2d-4ad1-9011-f0067e968688",
   "metadata": {},
   "source": [
    "### Food for Thought\n",
    "\n",
    "- What could be better heuristics for similarity resp. cost of substitution than the one above?\n",
    "- What about capitalization, punctiation and special characters?\n",
    "- What about swipe-to-type?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
